{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMnvtK7YQQx71HSlWNLj6yN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/payush55039/Project1LLM/blob/main/project1LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken matplotlib torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G6o-3OB87C1",
        "outputId": "ea70cd8c-3324-4e67-d313-b0229f184114"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "import matplotlib\n",
        "import tiktoken\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,    # Vocabulary size\n",
        "    \"context_length\": 1024, # Context length : represents the model's maximum input token count\n",
        "    \"emb_dim\": 768,         # Embedding dimension\n",
        "    \"n_heads\": 12,          # Number of attention heads\n",
        "    \"n_layers\": 12,         # Number of layers\n",
        "    \"drop_rate\": 0.1,       # Dropout rate\n",
        "    \"qkv_bias\": False       # Query-Key-Value bias\n",
        "}\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "batch =torch.randn(2, 5)\n",
        "\n",
        "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
        "out = layer(batch)\n",
        "\n",
        "\n",
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert (d_out % num_heads == 0), \\\n",
        "            \"d_out must be divisible by num_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\n",
        "            \"mask\",\n",
        "            torch.triu(torch.ones(context_length, context_length),\n",
        "                       diagonal=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if len(x.shape) == 2:\n",
        "            x = x.unsqueeze(1)\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec) # optional projection\n",
        "\n",
        "        return context_vec\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "batch_size, d_in = batch.shape # Only unpack 2 values\n",
        "context_length = batch.shape[1] # Assign context_length separately\n",
        "# batch_size, context_length, d_in = batch.shape # Original problematic line\n",
        "d_out = 2 # Output dimension\n",
        "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
        "out = mha(batch)\n",
        "\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        # Use a placeholder for TransformerBlock\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        # Use a placeholder for LayerNorm\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(\n",
        "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "        )\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim, eps=1e-5):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        x = (x - mean) / (std + self.eps)\n",
        "        x = self.scale * x + self.shift\n",
        "        return x\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval()\n",
        "class GPTDataset(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "def create_dataloader(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDataset(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "\n",
        "    return dataloader\n",
        "\n",
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    # idx is (batch, n_tokens) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_tokens, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probas = torch.softmax(logits, dim=-1)  # (batch, vocab_size)\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest probability value\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "x = torch.rand(2, 4, 768)  # Shape: [batch_size, num_tokens, emb_dim]\n",
        "block = TransformerBlock(GPT_CONFIG_124M)\n",
        "out = block(x)\n",
        "\n",
        "\n",
        "import os\n",
        "import urllib.request\n",
        "file_path = \"The Project Gutenberg eBook of Prid new.txt\"\n",
        "url = \"https://github.com/payush55039/Project1LLM/blob/1498a8148fd241c93a564a5f85f23e95d215f45e/The%20Project%20Gutenberg%20eBook%20of%20Prid%20new.txt\"\n",
        "if not os.path.exists(file_path):\n",
        "    urllib.request.urlretrieve(url, file_path)\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0) # remove batch dimension\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "start_context = \"Now, Kitty, you may cough as much as you choose,\"\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(start_context, tokenizer),\n",
        "    max_new_tokens=10,\n",
        "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text))\n",
        "train_data = text[:split_idx]\n",
        "val_data = text[split_idx:]\n",
        "train_loader = create_dataloader(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride= GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = create_dataloader(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n",
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
        "\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
        "\n",
        "\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 5\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
        "    start_context=\"Now, Kitty, you may cough as much as you choose,\", tokenizer=tokenizer\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(\"loss-plot.pdf\")\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 914
        },
        "id": "4pjibhM69CAF",
        "outputId": "1f8555cf-f928-4537-ed8a-3a2ace71cc96"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 8.943, Val loss 8.671\n",
            "Ep 1 (Step 000050): Train loss 5.330, Val loss 5.356\n",
            "Ep 1 (Step 000100): Train loss 5.348, Val loss 5.085\n",
            "Ep 1 (Step 000150): Train loss 4.836, Val loss 4.885\n",
            "Ep 1 (Step 000200): Train loss 4.733, Val loss 4.759\n",
            "Ep 1 (Step 000250): Train loss 4.645, Val loss 4.731\n",
            "Now, Kitty, you may cough as much as you choose, and\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\\n",
            "Ep 2 (Step 000300): Train loss 4.286, Val loss 4.653\n",
            "Ep 2 (Step 000350): Train loss 4.364, Val loss 4.640\n",
            "Ep 2 (Step 000400): Train loss 4.438, Val loss 4.598\n",
            "Ep 2 (Step 000450): Train loss 4.189, Val loss 4.552\n",
            "Ep 2 (Step 000500): Train loss 3.783, Val loss 4.513\n",
            "Ep 2 (Step 000550): Train loss 3.821, Val loss 4.477\n",
            "Now, Kitty, you may cough as much as you choose, and\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\\n",
            "Ep 3 (Step 000600): Train loss 4.317, Val loss 4.461\n",
            "Ep 3 (Step 000650): Train loss 3.628, Val loss 4.489\n",
            "Ep 3 (Step 000700): Train loss 3.951, Val loss 4.409\n",
            "Ep 3 (Step 000750): Train loss 3.974, Val loss 4.402\n",
            "Ep 3 (Step 000800): Train loss 3.789, Val loss 4.384\n",
            "Ep 3 (Step 000850): Train loss 3.799, Val loss 4.389\n",
            "Now, Kitty, you may cough as much as you choose, and\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\\n",
            "Ep 4 (Step 000900): Train loss 3.762, Val loss 4.353\n",
            "Ep 4 (Step 000950): Train loss 3.628, Val loss 4.335\n",
            "Ep 4 (Step 001000): Train loss 3.643, Val loss 4.348\n",
            "Ep 4 (Step 001050): Train loss 3.625, Val loss 4.341\n",
            "Ep 4 (Step 001100): Train loss 3.801, Val loss 4.314\n",
            "Ep 4 (Step 001150): Train loss 3.687, Val loss 4.296\n",
            "Now, Kitty, you may cough as much as you choose, and\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\\n",
            "Ep 5 (Step 001200): Train loss 3.310, Val loss 4.301\n",
            "Ep 5 (Step 001250): Train loss 3.198, Val loss 4.303\n",
            "Ep 5 (Step 001300): Train loss 3.347, Val loss 4.313\n",
            "Ep 5 (Step 001350): Train loss 3.201, Val loss 4.309\n",
            "Ep 5 (Step 001400): Train loss 3.179, Val loss 4.309\n",
            "Ep 5 (Step 001450): Train loss 3.283, Val loss 4.294\n",
            "Now, Kitty, you may cough as much as you choose, and\\r\",\"\\r\",\"\\r\",\"\\r\",\"’s a little, and that I had been a\\r\",\"\\r\",\"’s\\r\",\"\\r\",\"\\r\",\"\\r\",\"\\r\",\"�\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_path = input(\"Enter the file path: \")\n",
        "url = input(\"Enter the URL: \")\n",
        "\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    urllib.request.urlretrieve(url, file_path)\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "num_epochs=int(input(\"Enter the number of epochs: \"))\n",
        "train_model_simple(model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,start_context = input(\"Enter the starting context for text generation: \"),tokenizer=tokenizer)\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "     # Moved input here\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context # Use start_context from input\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen, start_context # Return start_context\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dzqEwkc_BndT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}